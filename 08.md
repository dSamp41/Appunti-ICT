# MITRE ATLAS 

<u>Def</u>: ==ATLAS== (Adversarial Threat Landscape for AI Systems) = adversary tactics and techniques based on real-world attack observations

<u>Prop</u>: machine learning attacks
- Model Evasion: Attacker modifies a query to get a desired outcome. These attacks iteratively query a model and observe the output.
- Functional Ext: Attacker recover a functionally equivalent model by iteratively querying the model. An attacker examines the offline copy of the model before further attacking the online model.
- Model Poisoning: Attacker contaminates the training data of an ML system to get a desired output. By manipulating training data an attacker creates "backdoors" that man an arbitrary input into a particular output to perform a new undesired task.
- Model Inversion: Attacker recovers the features used to train the model. A successful attack would result in an attacker being able to launch a Membership inference attack and compromise of private data.
- Traditional: Attacker uses well established TTPs to attain their goal.